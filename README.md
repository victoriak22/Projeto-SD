# Sistema de Mensagens InstantÃ¢neas - Projeto Completo

Sistema distribuÃ­do de mensagens instantÃ¢neas inspirado em BBS/IRC, desenvolvido para a disciplina de Sistemas DistribuÃ­dos.

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa um sistema completo de mensagens distribuÃ­das com:
- âœ… 5 Partes implementadas (Request-Reply, Pub/Sub, MessagePack, RelÃ³gios, ReplicaÃ§Ã£o)
- âœ… 3 Linguagens de programaÃ§Ã£o (Go, JavaScript/Node.js, Python)
- âœ… MÃºltiplos padrÃµes de comunicaÃ§Ã£o (REQ-REP, PUB-SUB)
- âœ… SincronizaÃ§Ã£o de relÃ³gios (Lamport + Berkeley)
- âœ… EleiÃ§Ã£o de coordenador (Bully)
- âœ… ReplicaÃ§Ã£o de dados (Primary-Backup)
- âœ… Alta disponibilidade e tolerÃ¢ncia a falhas

---

## ğŸ“‹ Parte 1: Request-Reply âœ…

ImplementaÃ§Ã£o do padrÃ£o Request-Reply para comunicaÃ§Ã£o entre cliente e servidor.

### Funcionalidades Implementadas

- âœ… **Login de usuÃ¡rios**: Cadastro de novos usuÃ¡rios no sistema
- âœ… **Listagem de usuÃ¡rios**: VisualizaÃ§Ã£o de todos os usuÃ¡rios cadastrados
- âœ… **CriaÃ§Ã£o de canais**: CriaÃ§Ã£o de novos canais de comunicaÃ§Ã£o
- âœ… **Listagem de canais**: VisualizaÃ§Ã£o de todos os canais disponÃ­veis
- âœ… **PersistÃªncia de dados**: Armazenamento em disco de logins e canais

---

## ğŸ“‹ Parte 2: Publisher-Subscriber âœ…

ImplementaÃ§Ã£o do padrÃ£o Pub/Sub para troca de mensagens entre usuÃ¡rios.

### Funcionalidades Implementadas

- âœ… **Broker Pub/Sub**: Proxy XSUB/XPUB para distribuiÃ§Ã£o de mensagens
- âœ… **PublicaÃ§Ã£o em canais**: UsuÃ¡rios podem publicar mensagens em canais pÃºblicos
- âœ… **Mensagens diretas**: Envio de mensagens privadas entre usuÃ¡rios
- âœ… **InscriÃ§Ã£o em canais**: UsuÃ¡rios podem se inscrever em canais para receber mensagens
- âœ… **Cliente automatizado**: Bots que geram mensagens aleatÃ³rias para testes
- âœ… **PersistÃªncia de mensagens**: Todas as mensagens sÃ£o armazenadas em disco

---

## ğŸ“‹ Parte 3: MessagePack âœ…

OtimizaÃ§Ã£o da serializaÃ§Ã£o de mensagens usando MessagePack ao invÃ©s de JSON.

### Funcionalidades Implementadas

- âœ… **SerializaÃ§Ã£o eficiente**: Mensagens em formato binÃ¡rio (MessagePack)
- âœ… **Compatibilidade entre linguagens**: Go, JavaScript e Python usando MessagePack
- âœ… **ReduÃ§Ã£o de tamanho**: Mensagens ~25% menores que JSON
- âœ… **Melhor performance**: SerializaÃ§Ã£o/deserializaÃ§Ã£o mais rÃ¡pida
- âœ… **Transparente**: Mesma funcionalidade, formato diferente

### ComparaÃ§Ã£o de Tamanho

**Exemplo: Login Request**

JSON (60 bytes):
```json
{"service":"login","data":{"user":"alice","timestamp":1234567890}}
```

MessagePack (~45 bytes - 25% menor):
```
\x82\xa7service\xa5login\xa4data\x82\xa4user\xa5alice\xa9timestamp\xce\x49\x96\x02\xd2
```

**Vantagens do MessagePack**:
- ğŸ“‰ Mensagens menores (15-30% de reduÃ§Ã£o)
- âš¡ SerializaÃ§Ã£o/deserializaÃ§Ã£o mais rÃ¡pida
- ğŸ”„ CompatÃ­vel entre diferentes linguagens
- ğŸ’¾ Menos uso de banda e memÃ³ria

---

## ğŸ“‹ Parte 4: RelÃ³gios âœ…

ImplementaÃ§Ã£o de relÃ³gios lÃ³gicos e fÃ­sicos para sincronizaÃ§Ã£o em sistemas distribuÃ­dos.

### Etapa 1: RelÃ³gio LÃ³gico de Lamport âœ…

ImplementaÃ§Ã£o de relÃ³gios lÃ³gicos para ordenaÃ§Ã£o de eventos distribuÃ­dos.

#### Funcionalidades

- âœ… **RelÃ³gio lÃ³gico em todos os processos**: Server, Client e Auto-client
- âœ… **Incremento antes de enviar**: `clock++` antes de cada envio
- âœ… **AtualizaÃ§Ã£o ao receber**: `clock = max(local, recebido) + 1`
- âœ… **Campo clock em todas as mensagens**: IncluÃ­do em requests e responses
- âœ… **Logs com clock**: Todas as operaÃ§Ãµes mostram o valor do relÃ³gio lÃ³gico

#### Como Funciona

**Algoritmo de Lamport:**
1. Cada processo mantÃ©m um contador (`logicalClock`)
2. Antes de enviar mensagem: incrementa o contador
3. Ao receber mensagem: `clock = max(clock_local, clock_recebido) + 1`

**Exemplo:**
```
Cliente envia login (clock=1) â†’ 
Servidor recebe (atualiza para clock=2) â†’
Servidor responde (clock=3) â†’
Cliente recebe (atualiza para clock=4)
```

### Etapa 2: Servidor de ReferÃªncia âœ…

Novo componente para gerenciar registro e descoberta de servidores.

#### Funcionalidades

- âœ… **Novo container `reference`**: Servidor de referÃªncia em Python (porta 5559)
- âœ… **ServiÃ§o `rank`**: Atribui rank Ãºnico a cada servidor
- âœ… **ServiÃ§o `list`**: Retorna lista de servidores ativos
- âœ… **ServiÃ§o `heartbeat`**: MantÃ©m lista de servidores atualizada
- âœ… **PersistÃªncia**: Salva lista de servidores em disco
- âœ… **Cleanup automÃ¡tico**: Remove servidores inativos (timeout 60s)
- âœ… **Heartbeat periÃ³dico**: A cada 10 segundos

#### Como Funciona

**Registro:**
1. Servidor inicia e conecta ao reference (porta 5559)
2. Envia requisiÃ§Ã£o `rank` com seu nome
3. Reference atribui rank Ãºnico (1, 2, 3, ...)
4. Servidor armazena seu rank

**Heartbeat:**
- Servidor envia heartbeat a cada 10 segundos
- Reference atualiza timestamp
- Servidores sem heartbeat por 60s sÃ£o removidos

### Etapa 3: MÃºltiplos Servidores âœ…

ConfiguraÃ§Ã£o de 3 rÃ©plicas do servidor para alta disponibilidade.

#### Funcionalidades

- âœ… **3 servidores independentes**: server-1, server-2, server-3
- âœ… **Ranks Ãºnicos**: 1, 2, 3
- âœ… **Dados independentes**: Cada servidor tem seu prÃ³prio volume
- âœ… **Portas diferentes**: 5555, 5556, 5557 (externamente)
- âœ… **Todos registrados**: Conectados ao reference
- âœ… **Heartbeats simultÃ¢neos**: Todos enviam heartbeat periÃ³dico

**ConfiguraÃ§Ã£o:**
```
server-1: porta 5555, rank 1, volume server-1-data
server-2: porta 5556, rank 2, volume server-2-data
server-3: porta 5557, rank 3, volume server-3-data
```

### Etapa 4: SincronizaÃ§Ã£o Berkeley âœ…

ImplementaÃ§Ã£o do Algoritmo de Berkeley para sincronizaÃ§Ã£o de relÃ³gios fÃ­sicos.

#### Funcionalidades

- âœ… **Coordenador eleito**: Servidor com maior rank
- âœ… **Coleta de timestamps**: Coordenador pede tempo de todos
- âœ… **CÃ¡lculo de mÃ©dia**: `mÃ©dia = soma(timestamps) / N`
- âœ… **DistribuiÃ§Ã£o de ajustes**: Envia ajuste individual para cada servidor
- âœ… **AplicaÃ§Ã£o de ajustes**: Servidores ajustam seus relÃ³gios
- âœ… **SincronizaÃ§Ã£o periÃ³dica**: A cada 10 mensagens processadas
- âœ… **Offset de tempo**: MantÃ©m ajuste sem modificar relÃ³gio do sistema

#### Como Funciona

**Algoritmo:**
1. Coordenador coleta timestamps: `T1=100, T2=110, T3=105`
2. Calcula mÃ©dia: `mÃ©dia = (100+110+105)/3 = 105`
3. Calcula ajustes: `A1=+5, A2=-5, A3=0`
4. Distribui ajustes para cada servidor
5. Todos sincronizados: `T1'=105, T2'=105, T3'=105`

**Logs esperados:**
```
ğŸ¯ Iniciando sincronizaÃ§Ã£o Berkeley como COORDENADOR
ğŸ“Š Coletando timestamps de 3 servidores...
   ğŸ“¥ server-1: 100
   ğŸ“¥ server-2: 110
ğŸ“Š Tempo mÃ©dio calculado: 105
   ğŸ“¤ Enviado ajuste de +5s para server-1
   ğŸ“¤ Enviado ajuste de -5s para server-2
âœ… SincronizaÃ§Ã£o Berkeley concluÃ­da
```

### Etapa 5: EleiÃ§Ã£o Bully âœ…

ImplementaÃ§Ã£o do Algoritmo Bully para eleiÃ§Ã£o automÃ¡tica de coordenador.

#### Funcionalidades

- âœ… **DetecÃ§Ã£o de falha**: Verifica coordenador a cada 30 segundos
- âœ… **Algoritmo Bully**: EleiÃ§Ã£o baseada em rank (maior vence)
- âœ… **Mensagens de eleiÃ§Ã£o**: Envia `election` para ranks maiores
- âœ… **Resposta OK**: Servidores maiores respondem e iniciam prÃ³pria eleiÃ§Ã£o
- âœ… **AnÃºncio de coordenador**: Publicado no tÃ³pico `servers`
- âœ… **SubscriÃ§Ã£o ao tÃ³pico**: Todos os servidores recebem anÃºncios
- âœ… **AtualizaÃ§Ã£o automÃ¡tica**: Todos atualizam coordenador atual
- âœ… **Coordenador inicial**: Determinado ao iniciar (maior rank)

#### Como Funciona

**Algoritmo Bully:**
1. Servidor detecta falha do coordenador
2. Envia `election` para todos com rank maior
3. Se alguÃ©m responde "OK": aguarda novo coordenador
4. Se ninguÃ©m responde: torna-se coordenador
5. Publica no tÃ³pico `servers`
6. Todos recebem e atualizam

**Exemplo:**
```
Estado inicial: server-3 (rank 3) Ã© coordenador

[server-3 falha]

server-2 detecta â†’ envia election â†’ timeout â†’ 
se torna coordenador â†’ publica no tÃ³pico 'servers'

server-1 recebe anÃºncio â†’ atualiza coordenador = server-2
```

**Logs esperados:**
```
âš ï¸ Coordenador server-3 nÃ£o respondeu - iniciando eleiÃ§Ã£o
ğŸ—³ï¸ Iniciando eleiÃ§Ã£o Bully...
ğŸ‘‘ NinguÃ©m respondeu. Me tornando coordenador!
ğŸ“¢ AnÃºncio de coordenador publicado no tÃ³pico 'servers'
```

---

## ğŸ“‹ Parte 5: ConsistÃªncia e ReplicaÃ§Ã£o âœ…

ImplementaÃ§Ã£o de replicaÃ§Ã£o de dados para garantir que todos os servidores tenham cÃ³pia completa dos dados.

### Problema

O broker distribui clientes entre servidores (load balancing). Consequentemente:
- âŒ Cada servidor possui apenas parte das mensagens
- âŒ Se um servidor falha, dados sÃ£o perdidos
- âŒ Clientes recebem histÃ³rico incompleto ao consultar um servidor especÃ­fico

### SoluÃ§Ã£o Implementada

**MÃ©todo escolhido: Primary-Backup com PropagaÃ§Ã£o AssÃ­ncrona**

AdaptaÃ§Ã£o do modelo Primary-Backup com as seguintes caracterÃ­sticas:

#### CaracterÃ­sticas do MÃ©todo

1. **Primary (Coordenador)**: 
   - Servidor com maior rank atua como primary
   - Determinado pelo algoritmo Bully
   - ResponsÃ¡vel por coordenar sincronizaÃ§Ã£o

2. **Backups**: 
   - Todos os outros servidores sÃ£o backups
   - Recebem replicaÃ§Ãµes do primary e de outros servidores
   - Podem promover-se a primary via eleiÃ§Ã£o

3. **PropagaÃ§Ã£o AssÃ­ncrona**:
   - ReplicaÃ§Ã£o nÃ£o bloqueia operaÃ§Ãµes do usuÃ¡rio
   - Executada em goroutines/threads separadas
   - Melhor performance mas janela de inconsistÃªncia temporÃ¡ria

4. **SincronizaÃ§Ã£o PeriÃ³dica**:
   - A cada 60 segundos, backups sincronizam com coordenador
   - Garante convergÃªncia para consistÃªncia eventual
   - Resolve inconsistÃªncias e preenche lacunas

5. **TolerÃ¢ncia a Falhas**:
   - EleiÃ§Ã£o Bully garante novo primary automaticamente
   - ReplicaÃ§Ã£o continua apÃ³s eleiÃ§Ã£o
   - Dados nÃ£o sÃ£o perdidos

### Funcionalidades Implementadas

- âœ… **ReplicaÃ§Ã£o automÃ¡tica**: Dados replicados para todos os servidores ao salvar
- âœ… **SincronizaÃ§Ã£o periÃ³dica**: A cada 60s, servidores solicitam sincronizaÃ§Ã£o completa
- âœ… **SincronizaÃ§Ã£o sob demanda**: ServiÃ§o `sync` para sincronizaÃ§Ã£o manual
- âœ… **ReplicaÃ§Ã£o assÃ­ncrona**: NÃ£o bloqueia operaÃ§Ãµes do usuÃ¡rio
- âœ… **Thread-safe**: Mutex protege acesso aos dados compartilhados
- âœ… **ConsistÃªncia eventual**: Todos os servidores convergem para o mesmo estado
- âœ… **Merge inteligente**: Previne duplicatas usando timestamps

### Tipos de Dados Replicados

1. **Logins** (`login`): Novos usuÃ¡rios cadastrados
2. **Canais** (`channel`): Novos canais criados
3. **Mensagens de Canal** (`channel_message`): PublicaÃ§Ãµes em canais
4. **Mensagens Diretas** (`user_message`): Mensagens entre usuÃ¡rios

### Fluxo de ReplicaÃ§Ã£o

**OperaÃ§Ã£o Normal:**
```
1. Cliente faz login no server-1
2. server-1 salva localmente
3. server-1 replica assincronamente para server-2 e server-3
4. server-2 e server-3 recebem e salvam
5. Todos os servidores tÃªm o login
```

**SincronizaÃ§Ã£o PeriÃ³dica:**
```
A cada 60 segundos:
1. Backups (server-1, server-2) solicitam sync do coordenador (server-3)
2. Coordenador envia todos os dados: logins, canais, mensagens
3. Backups fazem merge com dados locais
4. Duplicatas sÃ£o ignoradas (usando timestamp + username/channel)
5. Sistema converge para consistÃªncia
```

### Formato das Mensagens

**ReplicaÃ§Ã£o:**
```json
{
  "service": "replicate",
  "data": {
    "type": "login",
    "content": {
      "username": "alice",
      "timestamp": 1234567890
    },
    "timestamp": 1234567890,
    "clock": 42
  }
}
```

**SincronizaÃ§Ã£o Completa:**

Request:
```json
{
  "service": "sync",
  "data": {
    "last_sync": 1234567000,
    "timestamp": 1234567890,
    "clock": 50
  }
}
```

Response:
```json
{
  "service": "sync",
  "data": {
    "logins": [
      {"username": "alice", "timestamp": 1234567890},
      {"username": "bob", "timestamp": 1234567895}
    ],
    "channels": ["geral", "tech"],
    "channel_messages": [...],
    "user_messages": [...],
    "timestamp": 1234567890,
    "clock": 51
  }
}
```

### ModificaÃ§Ãµes no MÃ©todo Primary-Backup Tradicional

**DiferenÃ§as do Primary-Backup clÃ¡ssico:**

1. **ReplicaÃ§Ã£o Multi-Direcional**:
   - ClÃ¡ssico: Apenas primary replica para backups
   - **Nossa implementaÃ§Ã£o**: Qualquer servidor pode replicar para outros
   - Vantagem: Mesmo sem ser primary, servidor pode garantir dados replicados

2. **SincronizaÃ§Ã£o PeriÃ³dica Adicional**:
   - ClÃ¡ssico: Apenas replicaÃ§Ã£o sob demanda
   - **Nossa implementaÃ§Ã£o**: Sync periÃ³dica a cada 60s
   - Vantagem: AutocorreÃ§Ã£o de inconsistÃªncias

3. **EleiÃ§Ã£o AutomÃ¡tica de Primary**:
   - ClÃ¡ssico: Primary fixo ou manual
   - **Nossa implementaÃ§Ã£o**: Algoritmo Bully elege automaticamente
   - Vantagem: TolerÃ¢ncia a falhas sem intervenÃ§Ã£o

4. **AssÃ­ncrono com ConsistÃªncia Eventual**:
   - ClÃ¡ssico: Geralmente sÃ­ncrono (bloqueante)
   - **Nossa implementaÃ§Ã£o**: AssÃ­ncrono para performance
   - Trade-off: Janela de inconsistÃªncia aceitÃ¡vel

### Vantagens

âœ… **Performance**: ReplicaÃ§Ã£o assÃ­ncrona nÃ£o bloqueia cliente  
âœ… **Simplicidade**: Coordenador centraliza lÃ³gica de sincronizaÃ§Ã£o  
âœ… **TolerÃ¢ncia a Falhas**: EleiÃ§Ã£o automÃ¡tica + mÃºltiplos backups  
âœ… **ConsistÃªncia Eventual**: Sistema converge automaticamente  
âœ… **Escalabilidade**: FÃ¡cil adicionar novos servidores  
âœ… **AutocorreÃ§Ã£o**: SincronizaÃ§Ã£o periÃ³dica corrige inconsistÃªncias  

### Desvantagens e Trade-offs

âš ï¸ **Janela de InconsistÃªncia**: Breve perÃ­odo (< 60s) onde dados podem nÃ£o estar em todos  
âš ï¸ **Overhead de Rede**: Cada operaÃ§Ã£o gera N-1 replicaÃ§Ãµes  
âš ï¸ **Duplicatas PossÃ­veis**: Sync pode criar duplicatas temporÃ¡rias (aceitÃ¡veis)  
âš ï¸ **NÃ£o Ã© ACID forte**: ConsistÃªncia eventual, nÃ£o imediata  

### Garantias Fornecidas

âœ… **Disponibilidade**: Sistema continua funcionando com falhas  
âœ… **PartiÃ§Ã£o**: Tolera partiÃ§Ãµes de rede temporÃ¡rias  
âœ… **ConsistÃªncia Eventual**: Todos convergem para mesmo estado  
âœ… **Durabilidade**: Dados persistidos em mÃºltiplos servidores  

### Logs Esperados

```
Server-1 (recebe login):
âœ… Novo usuÃ¡rio cadastrado: alice (clock: 15)
ğŸ”„ Replicando login para 2 servidores...
   âœ… Replicado para server-2
   âœ… Replicado para server-3

Server-2 (recebe replicaÃ§Ã£o):
ğŸ”„ Login replicado: alice

Server-3 (recebe replicaÃ§Ã£o):
ğŸ”„ Login replicado: alice

[60 segundos depois]

Server-1 (sincronizaÃ§Ã£o periÃ³dica):
ğŸ”„ Solicitando sincronizaÃ§Ã£o completa de server-3...
âœ… SincronizaÃ§Ã£o recebida: 5 logins, 3 canais, 10 msgs canal, 5 msgs diretas
ğŸ”„ Merge de dados locais com dados sincronizados
âœ… SincronizaÃ§Ã£o completa concluÃ­da
```

---

## ğŸ—ï¸ Arquitetura Completa

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Reference  â”‚ :5559
                    â”‚  (Python)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†• REQ/REP
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                â†“                â†“
   Server-1         Server-2         Server-3 (Primary/Coordenador)
   rank=1           rank=2           rank=3
   :5555            :5556            :5557
        â†“                â†“                â†“
    [ReplicaÃ§Ã£o entre servidores]
    [SincronizaÃ§Ã£o Berkeley]
    [EleiÃ§Ã£o Bully]
        â†“                â†“                â†“
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Broker â”‚ :5557/:5558
                    â”‚(XSUB/XPUB)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
                  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                  â†“             â†“
              Client        Auto-Clients
           (Node.js)        (Python)
```

### Componentes

- **Reference**: Registro de servidores, ranks, heartbeats
- **Servers (3x)**: Request-Reply + Publisher + ReplicaÃ§Ã£o
- **Broker**: Pub/Sub proxy (XSUB/XPUB)
- **Client**: Interface CLI interativa
- **Auto-clients**: Bots geradores de carga

---

## ğŸ› ï¸ Tecnologias

- **Server**: Go 1.21 + ZeroMQ (REP + PUB) + MessagePack
- **Client**: Node.js 20 + ZeroMQ (REQ + SUB) + MessagePack
- **Broker**: Python 3.11 + ZeroMQ (XSUB/XPUB)
- **Reference**: Python 3.11 + ZeroMQ (REP) + MessagePack
- **Auto-client**: Python 3.11 + ZeroMQ (REQ) + MessagePack
- **ComunicaÃ§Ã£o**: ZeroMQ (Request-Reply + Pub/Sub)
- **SerializaÃ§Ã£o**: MessagePack (binÃ¡rio, eficiente)
- **PersistÃªncia**: JSON (legÃ­vel)
- **ContainerizaÃ§Ã£o**: Docker + Docker Compose

### Bibliotecas MessagePack

- **Go**: `github.com/vmihailenco/msgpack/v5`
- **JavaScript**: `@msgpack/msgpack`
- **Python**: `msgpack`

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Docker
- Docker Compose

### Iniciar o Sistema Completo

```bash
# Construir e iniciar todos os containers
docker-compose up --build

# Executar em background
docker-compose up -d --build
```

### Interagir com o Cliente

```bash
# Acessar cliente interativo
docker exec -it messaging-client npm start

# Ou criar novo cliente
docker-compose run --rm client npm start
```

### Testar MÃºltiplos Clientes

```bash
# Terminal 1 - Alice
docker-compose run --rm client npm start

# Terminal 2 - Bob
docker-compose run --rm client npm start

# Terminal 3 - Charlie
docker-compose run --rm client npm start
```

### Ver Logs

```bash
# Todos os serviÃ§os
docker-compose logs -f

# Servidores
docker-compose logs -f server-1 server-2 server-3

# Reference
docker-compose logs -f reference

# Broker
docker-compose logs -f broker

# Clientes automatizados
docker-compose logs -f auto-client-1 auto-client-2
```

### Parar o Sistema

```bash
# Parar containers
docker-compose down

# Limpar volumes (apaga dados)
docker-compose down -v
```

---

## ğŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ reference/
â”‚   â”œâ”€â”€ main.py              # Servidor de referÃªncia (Python)
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ broker/
â”‚   â”œâ”€â”€ main.py              # Broker Pub/Sub (Python)
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ main.go              # Servidor (Go)
â”‚   â”œâ”€â”€ go.mod
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ client/
â”‚   â”œâ”€â”€ main.js              # Cliente interativo (Node.js)
â”‚   â”œâ”€â”€ auto_client.py       # Cliente automatizado (Python)
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ Dockerfile.auto
â”œâ”€â”€ proxy/
â”‚   â””â”€â”€ main.py              # Placeholder
â”œâ”€â”€ docker-compose.yml       # OrquestraÃ§Ã£o (6 containers)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ ARCHITECTURE.md
```

---

## ğŸ§ª Testes Completos

### Teste 1: Request-Reply (Parte 1)

```bash
docker-compose up --build
docker-compose run --rm client npm start
```

1. Login como "alice"
2. Criar canal "geral"
3. Listar canais
4. Listar usuÃ¡rios

### Teste 2: Pub/Sub (Parte 2)

```bash
# Terminal 1 - Alice
docker-compose run --rm client npm start
# Login â†’ Inscrever canal "geral" â†’ Publicar mensagem

# Terminal 2 - Bob
docker-compose run --rm client npm start
# Login â†’ Inscrever canal "geral" â†’ Ver mensagens â†’ Enviar DM para Alice
```

### Teste 3: RelÃ³gios (Parte 4)

```bash
# Ver logs com clocks
docker-compose logs server-1 | grep "clock:"

# Fazer 10 operaÃ§Ãµes para forÃ§ar sincronizaÃ§Ã£o Berkeley
# Ver logs de sincronizaÃ§Ã£o
docker-compose logs server-3 | grep "Berkeley"
```

### Teste 4: EleiÃ§Ã£o (Parte 4)

```bash
# Parar coordenador
docker-compose stop server-3

# Aguardar 30s e ver eleiÃ§Ã£o
docker-compose logs server-2 | grep "eleiÃ§Ã£o"

# Deve mostrar: server-2 se torna coordenador
```

### Teste 5: ReplicaÃ§Ã£o (Parte 5)

```bash
# 1. Fazer login em server-1
docker-compose run --rm -e SERVER_URL=tcp://server-1:5555 client npm start
# Login como "teste_replicacao"

# 2. Verificar replicaÃ§Ã£o nos logs
docker-compose logs server-1 | grep "Replicando"
docker-compose logs server-2 | grep "replicado"
docker-compose logs server-3 | grep "replicado"

# 3. Verificar dados em todos os servidores
docker exec messaging-server-1 cat /data/server_data.json | grep "teste_replicacao"
docker exec messaging-server-2 cat /data/server_data.json | grep "teste_replicacao"
docker exec messaging-server-3 cat /data/server_data.json | grep "teste_replicacao"

# Todos devem ter o usuÃ¡rio!
```

---

## ğŸ“Š Logs e Debug

```bash
# Ver dados persistidos
docker exec messaging-server-1 cat /data/server_data.json
docker exec messaging-server-2 cat /data/server_data.json
docker exec messaging-server-3 cat /data/server_data.json

# Ver dados do reference
docker exec messaging-reference cat /data/reference_data.json

# Status dos containers
docker-compose ps

# Logs especÃ­ficos
docker-compose logs -f server-1
docker-compose logs -f reference
docker-compose logs -f broker
```

---

## ğŸ› Troubleshooting

### Cliente nÃ£o conecta
- Verifique containers: `docker-compose ps`
- Veja logs: `docker-compose logs server-1`
- Reinicie: `docker-compose restart server-1`

### Mensagens nÃ£o chegam
- Verifique broker: `docker-compose ps broker`
- Cliente inscrito no canal? (opÃ§Ã£o 5)
- Logs do broker: `docker-compose logs broker`

### ReplicaÃ§Ã£o nÃ£o funciona
- Verifique se 3 servidores estÃ£o ativos
- Veja logs: `docker-compose logs | grep "Replicando"`
- Verifique coordenador: `docker-compose logs | grep "Coordenador"`

### Erro ao buildar
- Limpe: `docker-compose down -v`
- Rebuild: `docker-compose build --no-cache`

### Dados nÃ£o persistem
- Verifique volumes: `docker volume ls | grep messaging`
- Veja conteÃºdo: `docker exec messaging-server-1 ls -la /data`

---

## ğŸ‘¥ Desenvolvimento

**Linguagens utilizadas:**
- **Go** (Server) - Request-Reply, Pub, RelÃ³gios, ReplicaÃ§Ã£o
- **JavaScript/Node.js** (Client) - CLI interativo
- **Python** (Broker, Reference, Auto-client)

**PadrÃµes implementados:**
- Request-Reply (REQ-REP)
- Publisher-Subscriber (PUB-SUB, XSUB-XPUB)
- RelÃ³gio LÃ³gico de Lamport
- SincronizaÃ§Ã£o de Berkeley
- EleiÃ§Ã£o Bully
- Primary-Backup com ReplicaÃ§Ã£o AssÃ­ncrona

---

## ğŸ“„ LicenÃ§a

MIT

---

## ğŸ‰ Status do Projeto

âœ… **Parte 1**: Request-Reply - COMPLETA  
âœ… **Parte 2**: Publisher-Subscriber - COMPLETA  
âœ… **Parte 3**: MessagePack - COMPLETA  
âœ… **Parte 4**: RelÃ³gios (5 etapas) - COMPLETA  
âœ… **Parte 5**: ConsistÃªncia e ReplicaÃ§Ã£o - COMPLETA  

**Projeto 100% ConcluÃ­do! ğŸŠ**